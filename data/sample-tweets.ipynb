{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import csv \n",
    "import pdb\n",
    "\n",
    "import gensim\n",
    "from gensim import matutils, corpora\n",
    "from gensim.models.ldamodel import LdaModel\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import statsmodels \n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "import snowball"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###\n",
    "# 1/15 -- switching to whitelisted tweets *only*!\n",
    "tweet_data = pd.read_csv(\"CancerReport-clean-whitelisted-en.txt\", delimiter=\"\\t\", low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###\n",
    "# now to analyze the retweet counts; first pull out just the retweets\n",
    "retweets = tweet_data[tweet_data[\"retweet\"] == True]\n",
    "unique_retweet_id_list = list(set(retweets[\"retweet_id_str\"].tolist())) \n",
    "# group the tweets by the tweet they are, erm, retweeting\n",
    "grouped_retweets = retweets.groupby(\"retweet_id_str\")\n",
    "# then count up retweets and extract original (retweeted) text\n",
    "# see code in snowball.py for doing this\n",
    "orig_tweet_texts, retweet_counts = snowball._count_up_retweets(grouped_retweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###\n",
    "# topic modeling\n",
    "# kept_indices are the set of indices corresponding to tweets not discarded as noise \n",
    "toked_tweets, kept_indices = snowball.build_gensim_corpus(orig_tweet_texts, split_up_by_tag=False)\n",
    "lda, gensim_corpus, dictionary = snowball.gen_lda_model(toked_tweets)\n",
    "inferred_topic_matrix = lda.inference(gensim_corpus)[0]\n",
    "# renorm, due to weirdness in gensim (???)\n",
    "row_sums = inferred_topic_matrix.sum(axis=1)\n",
    "inferred_topic_matrix = inferred_topic_matrix / row_sums[:, np.newaxis]\n",
    "# remove the tweets that were cleaned/not included in gensim corpus\n",
    "retweet_counts = [retweet_counts[idx] for idx in kept_indices]\n",
    "orig_tweet_texts = [orig_tweet_texts[idx] for idx in kept_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# estimate the topical composition of the original tweets\n",
    "orig_tweets_bow = [dictionary.doc2bow(tweet) for tweet in toked_tweets]\n",
    "orig_tweets_inferred_topics = [lda.get_document_topics(doc) for doc in orig_tweets_bow]\n",
    "\n",
    "# note: this is ascending order, so most re-tweeted are last.\n",
    "sorted_tweets = sorted(zip(retweet_counts, orig_tweet_texts, orig_tweets_inferred_topics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.008\n",
      "Model:                            OLS   Adj. R-squared:                  0.005\n",
      "Method:                 Least Squares   F-statistic:                     2.962\n",
      "Date:                Fri, 15 Jan 2016   Prob (F-statistic):            0.00164\n",
      "Time:                        08:42:47   Log-Likelihood:                -16533.\n",
      "No. Observations:                3468   AIC:                         3.309e+04\n",
      "Df Residuals:                    3458   BIC:                         3.315e+04\n",
      "Df Model:                           9                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [95.0% Conf. Int.]\n",
      "------------------------------------------------------------------------------\n",
      "x1             0.9947      2.724      0.365      0.715        -4.346     6.335\n",
      "x2            -1.0573      3.911     -0.270      0.787        -8.725     6.611\n",
      "x3             1.1793      1.564      0.754      0.451        -1.887     4.246\n",
      "x4             0.8948      1.536      0.583      0.560        -2.116     3.906\n",
      "x5             5.9777      1.860      3.214      0.001         2.332     9.624\n",
      "x6             0.5934      3.835      0.155      0.877        -6.925     8.112\n",
      "x7             2.0063      1.191      1.684      0.092        -0.329     4.342\n",
      "x8            15.5826      3.059      5.093      0.000         9.584    21.581\n",
      "x9             1.6829      1.506      1.118      0.264        -1.269     4.635\n",
      "x10            6.5861      2.760      2.386      0.017         1.174    11.998\n",
      "==============================================================================\n",
      "Omnibus:                     9700.945   Durbin-Watson:                   1.931\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):        280822736.917\n",
      "Skew:                          35.739   Prob(JB):                         0.00\n",
      "Kurtosis:                    1395.229   Cond. No.                         3.42\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "# this is just ordinary least squares (OLS)\n",
    "regression_results = sm.OLS(retweet_counts, inferred_topic_matrix).fit()\n",
    "print(regression_results.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "topic 1:\n",
      " 0.064*cancer + 0.058*cervical + 0.038*co + 0.036*http + 0.029*hpv + 0.017*women + 0.016*one + 0.014*th + 0.013*amp + 0.012*ve\n",
      "\n",
      "topic 2:\n",
      " 0.078*hpv + 0.041*vax + 0.038*tx + 0.034*vaxchoice + 0.031*get + 0.024*nohb + 0.019*think + 0.018*human + 0.017*pap + 0.016*anal\n",
      "\n",
      "topic 3:\n",
      " 0.137*co + 0.136*http + 0.102*hpv + 0.069*vaccine + 0.048*gardasil + 0.023*vaccines + 0.016*via + 0.012*health + 0.012*girls + 0.011*side\n",
      "\n",
      "topic 4:\n",
      " 0.100*co + 0.097*http + 0.069*hpv + 0.049*cancer + 0.039*cervical + 0.032*vaccine + 0.015*gardasil + 0.014*amp + 0.011*cancers + 0.010*risk\n",
      "\n",
      "topic 5:\n",
      " 0.076*pap + 0.039*cancer + 0.039*smears + 0.030*women + 0.027*amp + 0.027*smear + 0.027*cervical + 0.017*breast + 0.017*co + 0.015*http\n",
      "\n",
      "topic 6:\n",
      " 0.035*pap + 0.030*smear + 0.027*year + 0.026*new + 0.023*stop + 0.021*dr + 0.021*truth + 0.020*every + 0.019*gardasil + 0.018*co\n",
      "\n",
      "topic 7:\n",
      " 0.129*cancer + 0.116*cervical + 0.098*co + 0.093*http + 0.020*screening + 0.017*awareness + 0.013*amp + 0.013*prevention + 0.011*help + 0.010*week\n",
      "\n",
      "topic 8:\n",
      " 0.116*pap + 0.114*smear + 0.033*rt + 0.031*got + 0.029*hpv + 0.026*getting + 0.025*like + 0.020*get + 0.020*right + 0.018*know\n",
      "\n",
      "topic 9:\n",
      " 0.122*hpv + 0.084*co + 0.083*http + 0.053*vaccine + 0.029*girls + 0.022*vaccination + 0.015*boys + 0.015*cancer + 0.015*study + 0.011*men\n",
      "\n",
      "topic 10:\n",
      " 0.086*co + 0.080*gardasil + 0.056*http + 0.050*https + 0.032*hpv + 0.031*cdcwhistleblower + 0.023*le + 0.021*less + 0.020*de + 0.017*women\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# crude look at what these topics look like (top words in each)\n",
    "for topic_idx, topic in enumerate(lda.print_topics()):\n",
    "    print(\"topic %s:\\n %s\\n\" % (topic_idx+1, topic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _to_file(path, tweets, headers=[\"retweet count\", \"tweet\", \"topics\"]):\n",
    "    with open(path, 'w') as outf: \n",
    "        csv_w = csv.writer(outf)\n",
    "        csv_w.writerow(headers)\n",
    "        csv_w.writerows(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_to_file(\"50-most-retweeted.csv\", sorted_tweets[-50:])\n",
    "_to_file(\"50-least-retweeted.csv\", sorted_tweets[:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_tweet_probs_for_topic(t_idx, tweets, tweet_topic_tuples, k=20):\n",
    "    # t_idx should be zero-indexed!!!\n",
    "    probs = []\n",
    "    for tw in tweet_topic_tuples:\n",
    "        topic_d = dict(tw)\n",
    "        try:\n",
    "            prob = topic_d[t_idx]\n",
    "        except:\n",
    "            prob = 0\n",
    "        probs.append(prob)\n",
    "    \n",
    "    return probs \n",
    "\n",
    "def top_tweets_for_topics(t_idx, tweets, tweet_topic_tuples, k=20, write_out=True):\n",
    "    topic_probs = get_tweet_probs_for_topic(t_idx, tweets, tweet_topic_tuples, k=k)\n",
    "    sorted_by_t = sorted(zip(topic_probs, tweets), reverse=True)\n",
    "    if write_out: \n",
    "        with open(\"top-%s-tweets-topic-%s.csv\" % (k, t_idx+1), 'w') as outf:\n",
    "            csv_w = csv.writer(outf)\n",
    "            csv_w.writerows(sorted_by_t)\n",
    "    return sorted_by_t[:k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# now we sample representative tweets from top topics (per our regression)\n",
    "# these are 4,7,9 (when zero-indexd --corresponding to 5,8,10 above)\n",
    "topic5_tweets = top_tweets_for_topics(4, orig_tweet_texts, orig_tweets_inferred_topics, k=50)\n",
    "topic8_tweets = top_tweets_for_topics(7, orig_tweet_texts, orig_tweets_inferred_topics, k=50)\n",
    "topic10_tweets = top_tweets_for_topics(9, orig_tweet_texts, orig_tweets_inferred_topics, k=50)\n",
    "\n",
    "# for reference/contrast; this topic is totally uncorrelated\n",
    "topic2_tweets = top_tweets_for_topics(1, orig_tweet_texts, orig_tweets_inferred_topics, k=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
